%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%  Sample document for preparing papers to  "Avtomatika i Telemekhanika"
%%  charset=utf-8
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\documentclass[12pt]{a&t}
\usepackage{graphicx}
\usepackage{bm}
\usepackage{url}
\usepackage{multirow}

\usepackage{autonum}

\begin{document}  %%%!!!

\year{2020}
\title{Analysis of privilege learning and distillation models.}%
\thanks{This research was supported by \dots}

\authors{A.V.~GRABOVOY\\
(Moscow Institute of Physics and Technology, Moscow)\\
V.V.~STRIJOV, Doctor of Science in physics and mathematics\\
(A.A. Dorodnicyn Computing Center, Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences)}

\maketitle

\begin{abstract}
This work analyses the methods for reducing the complexity of approximating models. The paper proposes the probabilistic approach of distillation and privilege learning methods. The article presents an analysis of the parametric function with a fixed structure. The paper shows a theoretical approach for the cases: linear and logistic regression. The theoretical results are analyzed in a computational experiment on synthetic datasets and real data. The computational experiment is using FashionMNIST and Twitter Sentiment Analysis datasets as real data.

\smallskip\\
\textit{Key words}: model selection; bayesian inference; distillation; privilege learning.
\end{abstract}

\AdditionalInformation{Grabovoy A.V.}{Moscow Institute of Physics and Technology, student, Moscow}{grabovoy.av@phystech.edu}

\AdditionalInformation{Strijov V.V.}{A.A. Dorodnicyn Computing Center, Federal Research Center ``Computer Science and Control'' of the Russian Academy of Sciences, leading scientist, Moscow}{strijov@phystech.edu}


\end{document}
