{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "Y = []\n",
    "\n",
    "with open('./Sentiment Analysis Dataset.csv') as inp:\n",
    "    csv_reader = csv.reader(inp, delimiter=',')\n",
    "    for i, line in enumerate(csv_reader):\n",
    "        if i > 0:\n",
    "            X.append(line[-1].strip())\n",
    "            Y.append(line[-3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y[8834] = '1'\n",
    "Y[535880] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('embedings.pkl', 'rb') as f:\n",
    "    emb = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1578614, 1578614, 1578614)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(emb), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Teacher(nn.Module):\n",
    "    def __init__(self, device = 'cpu'):\n",
    "        super(Teacher, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(768, 2)\n",
    "        \n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        r\"\"\"\n",
    "        :param input:\n",
    "        \"\"\"\n",
    "        out = self.linear(input)\n",
    "        return out\n",
    "    \n",
    "    \n",
    "class Student(nn.Module):\n",
    "    def __init__(self, vocabulary_size, device = 'cpu'):\n",
    "        super(Student, self).__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(vocabulary_size, 100)\n",
    "        \n",
    "        self.bi_LSTM = nn.LSTM(embedding_dim, 100, bidirectional = True)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = 0.5)\n",
    "        \n",
    "        self.linear = nn.Linear(200, 3)\n",
    "        self.to(device)\n",
    "        \n",
    "    def forward(self, input):\n",
    "        r\"\"\"\n",
    "        :param input:\n",
    "        \"\"\"\n",
    "        out = self.embedding(input)\n",
    "        \n",
    "        out, _ = self.bi_LSTM(out)\n",
    "        \n",
    "        out = self.dropout(out)\n",
    "        out = self.linear(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "indexes = np.arange(0, len(X))\n",
    "train_index, test_index = train_test_split(indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array(X)[train_index]\n",
    "X_test = np.array(X)[test_index]\n",
    "\n",
    "emb_train = emb[train_index]\n",
    "emb_test = emb[test_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(Y, dtype=np.int64)[train_index]\n",
    "Y_test = np.array(Y, dtype=np.int64)[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher = Teacher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Student without teacher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "student = Student()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = dict()\n",
    "vocabulary['<UNK>'] = 0\n",
    "\n",
    "for line in X_train:\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def BatchGenerator(dataset, batch_size=64, shuffle=True, device=device):\n",
    "    X, Y = dataset\n",
    "    n_samples = len(X)\n",
    "\n",
    "# генерим список индексов\n",
    "    list_of_indexes = np.linspace(0, n_samples - 1, n_samples, dtype=np.int64)\n",
    "    List_X = []\n",
    "    List_Y = []\n",
    "    \n",
    "# если нужно перемешать, то перемешиваем\n",
    "    if shuffle:\n",
    "        np.random.shuffle(list_of_indexes)\n",
    "        \n",
    "# сгенерировал список индексов, по этим индексам, \n",
    "# сделаем новый перемешаный спиисок токенов и тэгов\n",
    "    \n",
    "    n_batches = n_samples//batch_size\n",
    "    if n_samples%batch_size != 0:\n",
    "        n_batches+=1\n",
    "        \n",
    "    # For each k yield pair x and y\n",
    "    for k in range(n_batches):\n",
    "# указываем текущии размер батча\n",
    "        this_batch_size = batch_size\n",
    "    \n",
    "# если мы выдаем последний батч, то его нужно обрезать\n",
    "        if k == n_batches - 1:\n",
    "            if n_samples%batch_size > 0:\n",
    "                this_batch_size = n_samples%batch_size\n",
    "                \n",
    "        This_indexes = \n",
    "                \n",
    "        This_X = List_X[k*batch_size:k*batch_size + this_batch_size]\n",
    "        This_Y = List_Y[k*batch_size:k*batch_size + this_batch_size]\n",
    "        \n",
    "        This_X_line = [' '.join(sent) for sent in This_X]\n",
    "        \n",
    "        y_batch_ind = [IndexingAnswerSent(sent) for sent in This_Y]\n",
    "        \n",
    "        tokens = tokenizer(This_X_line, return_tensors='pt', padding=True)\n",
    "        mask = tokens['attention_mask']\n",
    "        x_batch_embeded = encoder(input_ids=tokens['input_ids'], attention_mask=mask)[0].detach()\n",
    "        \n",
    "        emb_dim_token = x_batch_embeded.shape[2]\n",
    "        \n",
    "        length_of_sentence = x_batch_embeded.shape[1]\n",
    "        \n",
    "        answ_arr = np.ones(shape=[this_batch_size, length_of_sentence])*PAD\n",
    "\n",
    "        for i in range(this_batch_size):\n",
    "            toks = tokenizer.tokenize(This_X_line[i])\n",
    "            toks_mapping = get_mapping(toks)\n",
    "            \n",
    "            for t in range(len(toks)):\n",
    "                answ_arr[i, t+1] = y_batch_ind[i][toks_mapping[t]]\n",
    "\n",
    "\n",
    "        x = x_batch_embeded.to(device)\n",
    "        answ = torch.LongTensor(answ_arr).to(device)\n",
    "\n",
    "        yield x, mask, answ\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
